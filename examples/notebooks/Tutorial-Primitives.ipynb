{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66880e8-23d9-4f00-b120-7f289f682511",
   "metadata": {},
   "source": [
    "# TextGrad Tutorials: Primitives\n",
    "\n",
    "![TextGrad](https://github.com/vinid/data/blob/master/logo_full.png?raw=true)\n",
    "\n",
    "An autograd engine -- for textual gradients!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zou-group/TextGrad/blob/main/examples/notebooks/Prompt-Optimization.ipynb)\n",
    "[![GitHub license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)\n",
    "[![Arxiv](https://img.shields.io/badge/arXiv-2406.07496-B31B1B.svg)](https://arxiv.org/abs/2406.07496)\n",
    "[![Documentation Status](https://readthedocs.org/projects/textgrad/badge/?version=latest)](https://textgrad.readthedocs.io/en/latest/?badge=latest)\n",
    "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/textgrad)](https://pypi.org/project/textgrad/)\n",
    "[![PyPI](https://img.shields.io/pypi/v/textgrad)](https://pypi.org/project/textgrad/)\n",
    "\n",
    "**Objectives for this tutorial:**\n",
    "\n",
    "* Introduce you to the primitives in TextGrad\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "* You need to have an OpenAI API key to run this tutorial. This should be set as an environment variable as OPENAI_API_KEY.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5e8935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/austintimberlake/Desktop/textgrad\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: openai>=1.23.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (2.15.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (9.1.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (2.3.3)\n",
      "Requirement already satisfied: platformdirs>=3.11.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (4.5.1)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (4.4.2)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (5.6.3)\n",
      "Requirement already satisfied: graphviz>=0.20.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (0.21)\n",
      "Requirement already satisfied: gdown>=5.2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (5.2.1)\n",
      "Requirement already satisfied: litellm>=1.49.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (1.80.16)\n",
      "Requirement already satisfied: pillow in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (12.1.0)\n",
      "Requirement already satisfied: httpx in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad==0.1.8) (0.28.1)\n",
      "Requirement already satisfied: filelock in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (2.4.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: packaging in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (6.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from gdown>=5.2.0->textgrad==0.1.8) (4.14.3)\n",
      "Requirement already satisfied: anyio in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad==0.1.8) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad==0.1.8) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad==0.1.8) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad==0.1.8) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpcore==1.*->httpx->textgrad==0.1.8) (0.16.0)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (3.13.3)\n",
      "Requirement already satisfied: click in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (1.76.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (4.26.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (2.12.5)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (0.22.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad==0.1.8) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad==0.1.8) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad==0.1.8) (4.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad==0.1.8) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad==0.1.8) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad==0.1.8) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad==0.1.8) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad==0.1.8) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad==0.1.8) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad==0.1.8) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad==0.1.8) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad==0.1.8) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad==0.1.8) (1.22.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad==0.1.8) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad==0.1.8) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad==0.1.8) (0.21.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.49.5->textgrad==0.1.8) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.49.5->textgrad==0.1.8) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad==0.1.8) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad==0.1.8) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad==0.1.8) (0.30.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad==0.1.8) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad==0.1.8) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad==0.1.8) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->textgrad==0.1.8) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad==0.1.8) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad==0.1.8) (2.6.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm>=1.49.5->textgrad==0.1.8) (2025.11.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from beautifulsoup4->gdown>=5.2.0->textgrad==0.1.8) (2.8.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from requests[socks]->gdown>=5.2.0->textgrad==0.1.8) (1.7.1)\n",
      "Building wheels for collected packages: textgrad\n",
      "  Building editable for textgrad (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for textgrad: filename=textgrad-0.1.8-0.editable-py3-none-any.whl size=9866 sha256=4dd67bdbe7dd0c5d87aa9e5aa56280d3f55100b8a62f3821de6b8b063cb31009\n",
      "  Stored in directory: /private/var/folders/fd/ntt6v6ts64x_yhx3c3054zv00000gn/T/pip-ephem-wheel-cache-43d7hkot/wheels/31/6c/b3/1bcc883beb125269ce5253459fb3951302e0ab797bda886328\n",
      "Successfully built textgrad\n",
      "Installing collected packages: textgrad\n",
      "  Attempting uninstall: textgrad\n",
      "    Found existing installation: textgrad 0.1.8\n",
      "    Uninstalling textgrad-0.1.8:\n",
      "      Successfully uninstalled textgrad-0.1.8\n",
      "Successfully installed textgrad-0.1.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a9c615-17a0-455c-8f9c-f0d25fb8824b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:10.594204491Z",
     "start_time": "2024-06-11T15:43:10.589328053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textgrad in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (0.1.8)\n",
      "Requirement already satisfied: openai>=1.23.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (2.15.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (9.1.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (2.3.3)\n",
      "Requirement already satisfied: platformdirs>=3.11.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (4.5.1)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (4.4.2)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (5.6.3)\n",
      "Requirement already satisfied: graphviz>=0.20.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (0.21)\n",
      "Requirement already satisfied: gdown>=5.2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (5.2.1)\n",
      "Requirement already satisfied: litellm>=1.49.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (1.80.16)\n",
      "Requirement already satisfied: pillow in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (12.1.0)\n",
      "Requirement already satisfied: httpx in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from textgrad) (0.28.1)\n",
      "Requirement already satisfied: filelock in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (2.4.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (1.3.1)\n",
      "Requirement already satisfied: packaging in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (6.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from gdown>=5.2.0->textgrad) (4.14.3)\n",
      "Requirement already satisfied: anyio in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpx->textgrad) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from httpcore==1.*->httpx->textgrad) (0.16.0)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (3.13.3)\n",
      "Requirement already satisfied: click in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (1.76.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (4.26.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (2.12.5)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from litellm>=1.49.5->textgrad) (0.22.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from openai>=1.23.6->textgrad) (4.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.49.5->textgrad) (1.22.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad) (0.21.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.49.5->textgrad) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.49.5->textgrad) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad) (0.30.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->textgrad) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (2.6.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm>=1.49.5->textgrad) (2025.11.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from beautifulsoup4->gdown>=5.2.0->textgrad) (2.8.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from requests[socks]->gdown>=5.2.0->textgrad) (1.7.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install textgrad # you might need to restart the notebook after installing textgrad\n",
    "\n",
    "from textgrad.engine import get_engine\n",
    "from textgrad import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887fbed36c7daf2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Variable\n",
    "\n",
    "Variables in TextGrad are the metaphorical equivalent of tensors in PyTorch. They are the primary data structure that you will interact with when using TextGrad. \n",
    "\n",
    "Variables keep track of gradients and manage the data.\n",
    "\n",
    "Variables require two arguments (and there is an optional third one):\n",
    "\n",
    "1. `data`: The data that the variable will hold\n",
    "2. `role_description`: A description of the role of the variable in the computation graph\n",
    "3. `requires_grad`: (optional) A boolean flag that indicates whether the variable requires gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65fb4456d84c8fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:17.669096228Z",
     "start_time": "2024-06-11T15:43:17.665325560Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = Variable(\"A sntence with a typo\", role_description=\"The input sentence\", requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65857dd50408ebd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:18.184004948Z",
     "start_time": "2024-06-11T15:43:18.178187640Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6a6921a1cce6a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Engine\n",
    "\n",
    "When we talk about the engine in TextGrad, we are referring to an LLM. The engine is an abstraction we use to interact with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281644022ac1c65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:32.606319032Z",
     "start_time": "2024-06-11T15:44:32.561460448Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "engine = get_engine(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53a561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentence \"The quick brown fox jumps over the lazy dog.\" is correct. It is a pangram, meaning it contains every letter of the English alphabet at least once.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT-5 mini with a custom system prompt and input\n",
    "engine = get_engine(\"gpt-4o-mini\")\n",
    "custom_system_prompt = \"Evaluate the correctness of this sentence\"\n",
    "custom_input = \"The quick brown fox jumps over the lazy dog.\"\n",
    "engine.generate(custom_input, system_prompt=custom_system_prompt, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7d6eaa115cd6a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This object behaves like you would expect an LLM to behave: You can sample generation from the engine using the `generate` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37502bf67ef23c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T17:29:41.108552705Z",
     "start_time": "2024-06-11T17:29:40.294256814Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.generate(\"Hello how are you?\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627edc07c0d3737",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Loss\n",
    "\n",
    "Again, Loss in TextGrad is the metaphorical equivalent of loss in PyTorch. We use Losses in different form in TextGrad but for now we will focus on a simple TextLoss. TextLoss is going to evaluate the loss wrt a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252e0a0152b81f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:32.894722136Z",
     "start_time": "2024-06-11T15:44:32.890708561Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = Variable(\"Evaluate the correctness of this sentence\", role_description=\"The system prompt\")\n",
    "loss = TextLoss(system_prompt, engine=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff137c99e0659dcc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f05ec2bf907b3ba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Optimizer\n",
    "\n",
    "Keeping on the analogy with PyTorch, the optimizer in TextGrad is the object that will update the parameters of the model. In this case, the parameters are the variables that have `requires_grad` set to `True`.\n",
    "\n",
    "**NOTE** This is a text optimizer! It will do all operations with text! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f93f80b9e3ad36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:33.741130951Z",
     "start_time": "2024-06-11T15:44:33.734977769Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = TextualGradientDescent(parameters=[x], engine=engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26883eb74ce0d01",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Putting it all together\n",
    "\n",
    "We can now put all the pieces together. We have a variable, an engine, a loss, and an optimizer. We can now run a single optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9817e0ae0179376d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:41.730132530Z",
     "start_time": "2024-06-11T15:44:34.997777872Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "l = loss(x)\n",
    "l.backward(engine)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77e3fab0efdd579e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:41.738985151Z",
     "start_time": "2024-06-11T15:44:41.731989729Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notice the typo in this sentence.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8aab93b80fb82c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "While here it is not going to be useful, we can also do multiple optimization steps in a loop! Do not forget to reset the gradients after each step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bb8d0dcc2539d1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T15:44:30.989940227Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a84aad4cd58737",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16a0ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     63\u001b[39m loss_input = F.sum(\n\u001b[32m     64\u001b[39m     [\n\u001b[32m     65\u001b[39m         Variable(\u001b[33m\"\u001b[39m\u001b[33mSentence:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, role_description=\u001b[33m\"\u001b[39m\u001b[33mloss prefix\u001b[39m\u001b[33m\"\u001b[39m, requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m     ]\n\u001b[32m     70\u001b[39m )\n\u001b[32m     72\u001b[39m l = loss(loss_input)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43ml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m optimizer.step()\n\u001b[32m     75\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/textgrad/variable.py:189\u001b[39m, in \u001b[36mVariable.backward\u001b[39m\u001b[34m(self, engine)\u001b[39m\n\u001b[32m    187\u001b[39m v.gradients = _check_and_reduce_gradients(v, backward_engine)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m v.get_grad_fn() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/textgrad/autograd/function.py:57\u001b[39m, in \u001b[36mBackwardContext.__call__\u001b[39m\u001b[34m(self, backward_engine)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, backward_engine: EngineLM):\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/textgrad/autograd/llm_ops.py:96\u001b[39m, in \u001b[36mLLMCall.backward\u001b[39m\u001b[34m(self, response, prompt, system_prompt, backward_engine)\u001b[39m\n\u001b[32m     94\u001b[39m children_variables = response.predecessors\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.get_gradient_text() == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backward_through_llm_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchildren_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackward_engine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mself\u001b[39m._backward_through_llm_chain(children_variables, response, prompt, system_prompt, backward_engine)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/textgrad/autograd/llm_ops.py:210\u001b[39m, in \u001b[36mLLMCall._backward_through_llm_base\u001b[39m\u001b[34m(variables, response, prompt, system_prompt, backward_engine)\u001b[39m\n\u001b[32m    207\u001b[39m backward_prompt = LLMCall._construct_llm_base_backward_prompt(backward_info)\n\u001b[32m    209\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m_backward_through_llm prompt\u001b[39m\u001b[33m\"\u001b[39m, extra={\u001b[33m\"\u001b[39m\u001b[33m_backward_through_llm\u001b[39m\u001b[33m\"\u001b[39m: backward_prompt})\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m gradient_value = \u001b[43mbackward_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackward_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBACKWARD_SYSTEM_PROMPT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m_backward_through_llm gradient\u001b[39m\u001b[33m\"\u001b[39m, extra={\u001b[33m\"\u001b[39m\u001b[33m_backward_through_llm\u001b[39m\u001b[33m\"\u001b[39m: gradient_value})\n\u001b[32m    213\u001b[39m conversation = CONVERSATION_TEMPLATE.format(**backward_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/textgrad/engine/openai.py:111\u001b[39m, in \u001b[36mBaseOpenAIEngine.__call__\u001b[39m\u001b[34m(self, prompt, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/textgrad/engine/openai.py:54\u001b[39m, in \u001b[36mBaseOpenAIEngine.generate\u001b[39m\u001b[34m(self, content, system_prompt, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;129m@retry\u001b[39m(wait=wait_random_exponential(\u001b[38;5;28mmin\u001b[39m=\u001b[32m1\u001b[39m, \u001b[38;5;28mmax\u001b[39m=\u001b[32m5\u001b[39m), stop=stop_after_attempt(\u001b[32m5\u001b[39m))\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     **kwargs,\n\u001b[32m     52\u001b[39m ):\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_from_single_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     59\u001b[39m         has_multimodal_input = \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/textgrad/engine/openai.py:104\u001b[39m, in \u001b[36mBaseOpenAIEngine._generate_from_single_prompt\u001b[39m\u001b[34m(self, prompt, system_prompt, temperature, max_tokens, top_p)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m     request_params[\u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m] = max_tokens\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m response = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m    107\u001b[39m \u001b[38;5;28mself\u001b[39m._save_cache(sys_prompt_arg + prompt, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/textgrad/.venv312/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/lib/python3.12/ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Chain an LLM call into a TextGrad optimization step\n",
    "# with a numeric blackbox judge in the loop.\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "from textgrad import BlackboxLLM\n",
    "from textgrad.autograd import functional as F\n",
    "\n",
    "polite_system_prompt = Variable(\n",
    "    \"You are a helpful assistant. Respond with a short sentence.\",\n",
    "    role_description=\"System prompt for generating a sentence\",\n",
    "    requires_grad=True,\n",
    ")\n",
    "\n",
    "generate_sentence_prompt = Variable(\n",
    "    f\"Try to say something to get out of an awkward situation. Output only the sentence you want to say. Nonce: {uuid.uuid4()}\",\n",
    "    role_description=\"User prompt for sentence generation\",\n",
    "    requires_grad=False,\n",
    ")\n",
    "\n",
    "model = BlackboxLLM(engine=engine, system_prompt=polite_system_prompt)\n",
    "raw_sentence = model(generate_sentence_prompt)\n",
    "\n",
    "judge_engine = get_engine(\"gpt-4o-mini\")\n",
    "\n",
    "def judge_politeness_score(text: str) -> int:\n",
    "    judge_prompt = (\n",
    "        \"You are a strict politeness judge. Rate the politeness of the sentence from 1 to 10. \"\n",
    "        \"Respond with only a single integer from 1 to 10.\"\n",
    "    )\n",
    "    response = judge_engine.generate(\n",
    "        f\"{judge_prompt}\\nSentence: {text}\",\n",
    "        temperature=0,\n",
    "    )\n",
    "    match = re.search(r\"\\d+\", response)\n",
    "    if not match:\n",
    "        return 1\n",
    "    score = int(match.group(0))\n",
    "    return max(1, min(10, score))\n",
    "\n",
    "# Use a fixed evaluation prompt and optimize the generation system prompt.\n",
    "# The blackbox judge only provides a numeric score; TextGrad uses it as context.\n",
    "eval_system_prompt = Variable(\n",
    "    \"You will receive a sentence and a politeness score from a separate blackbox judge. \"\n",
    "    \"Explain how to improve the sentence to increase the score toward 10. Be concise and actionable.\",\n",
    "    role_description=\"The system prompt\",\n",
    "    requires_grad=False,\n",
    ")\n",
    "loss = TextLoss(eval_system_prompt, engine=engine)\n",
    "optimizer = TextualGradientDescent(parameters=[polite_system_prompt], engine=engine)\n",
    "\n",
    "for step in range(20):\n",
    "    # Re-generate first so the loss is computed on the current prompt.\n",
    "    raw_sentence = model(generate_sentence_prompt)\n",
    "\n",
    "    score = judge_politeness_score(raw_sentence.value)\n",
    "    score_var = Variable(\n",
    "        f\"Politeness score (1-10) from blackbox judge: {score}\",\n",
    "        role_description=\"numeric politeness score\",\n",
    "        requires_grad=False,\n",
    "    )\n",
    "\n",
    "    loss_input = F.sum(\n",
    "        [\n",
    "            Variable(\"Sentence:\\n\", role_description=\"loss prefix\", requires_grad=False),\n",
    "            raw_sentence,\n",
    "            Variable(\"\\n\", role_description=\"loss separator\", requires_grad=False),\n",
    "            score_var,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    l = loss(loss_input)\n",
    "    l.backward(engine)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Step {step + 1} system prompt:\")\n",
    "    print(polite_system_prompt.value)\n",
    "    print(\"LLM output:\")\n",
    "    print(raw_sentence.value)\n",
    "    print(f\"Blackbox score: {score}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e6d7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rich in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (14.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from rich) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from rich) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/austintimberlake/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/austintimberlake/.pyenv/versions/3.12.7/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/austintimberlake/.pyenv/versions/3.12.7/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/fd/ntt6v6ts64x_yhx3c3054zv00000gn/T/ipykernel_43196/1134072749.py\", line 6, in <module>\n",
      "    from ssr.lens import Lens\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/external/subspace-rerouting/ssr/lens.py\", line 15, in <module>\n",
      "    import torch as t\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/austintimberlake/Desktop/textgrad/.venv312/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/austintimberlake/Desktop/textgrad/external/subspace-rerouting\")\n",
    "\n",
    "%pip install rich\n",
    "\n",
    "from ssr.lens import Lens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
