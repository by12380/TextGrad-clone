{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66880e8-23d9-4f00-b120-7f289f682511",
   "metadata": {},
   "source": [
    "# TextGrad Tutorials: Primitives\n",
    "\n",
    "![TextGrad](https://github.com/vinid/data/blob/master/logo_full.png?raw=true)\n",
    "\n",
    "An autograd engine -- for textual gradients!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zou-group/TextGrad/blob/main/examples/notebooks/Prompt-Optimization.ipynb)\n",
    "[![GitHub license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)\n",
    "[![Arxiv](https://img.shields.io/badge/arXiv-2406.07496-B31B1B.svg)](https://arxiv.org/abs/2406.07496)\n",
    "[![Documentation Status](https://readthedocs.org/projects/textgrad/badge/?version=latest)](https://textgrad.readthedocs.io/en/latest/?badge=latest)\n",
    "[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/textgrad)](https://pypi.org/project/textgrad/)\n",
    "[![PyPI](https://img.shields.io/pypi/v/textgrad)](https://pypi.org/project/textgrad/)\n",
    "\n",
    "**Objectives for this tutorial:**\n",
    "\n",
    "* Introduce you to the primitives in TextGrad\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "* You need to have an OpenAI API key to run this tutorial. This should be set as an environment variable as OPENAI_API_KEY.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5e8935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///Users/austintimberlake/Desktop/textgrad\n",
      "Requirement already satisfied: openai>=1.23.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (2.15.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (9.1.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (2.3.3)\n",
      "Requirement already satisfied: platformdirs>=3.11.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (4.4.0)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (4.4.2)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (5.6.3)\n",
      "Requirement already satisfied: graphviz>=0.20.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (0.21)\n",
      "Requirement already satisfied: gdown>=5.2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (5.2.0)\n",
      "Requirement already satisfied: litellm>=1.49.5 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (1.80.13)\n",
      "Requirement already satisfied: pillow in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (11.3.0)\n",
      "Requirement already satisfied: httpx in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad==0.1.8) (0.28.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (21.0.0)\n",
      "Requirement already satisfied: xxhash in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (3.6.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (4.67.1)\n",
      "Requirement already satisfied: packaging in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (0.70.18)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (6.0.3)\n",
      "Requirement already satisfied: filelock in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (3.19.1)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (3.13.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (1.22.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (6.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad==0.1.8) (4.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from gdown>=5.2.0->textgrad==0.1.8) (4.14.3)\n",
      "Requirement already satisfied: certifi in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad==0.1.8) (2026.1.4)\n",
      "Requirement already satisfied: anyio in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad==0.1.8) (4.12.1)\n",
      "Requirement already satisfied: idna in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad==0.1.8) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad==0.1.8) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->textgrad==0.1.8) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad==0.1.8) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad==0.1.8) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad==0.1.8) (0.21.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (3.1.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (2.12.5)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (8.7.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (4.25.1)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (1.76.0)\n",
      "Requirement already satisfied: tokenizers in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (0.22.2)\n",
      "Requirement already satisfied: click in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (8.1.8)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (0.14.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad==0.1.8) (0.12.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=6.8.0->litellm>=1.49.5->textgrad==0.1.8) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.49.5->textgrad==0.1.8) (3.0.3)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad==0.1.8) (0.27.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad==0.1.8) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad==0.1.8) (0.36.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from openai>=1.23.6->textgrad==0.1.8) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from openai>=1.23.6->textgrad==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from openai>=1.23.6->textgrad==0.1.8) (0.12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->textgrad==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pandas>=1.5.3->textgrad==0.1.8) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pandas>=1.5.3->textgrad==0.1.8) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pandas>=1.5.3->textgrad==0.1.8) (2025.3)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad==0.1.8) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad==0.1.8) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad==0.1.8) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->textgrad==0.1.8) (1.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad==0.1.8) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad==0.1.8) (2.6.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from tiktoken>=0.7.0->litellm>=1.49.5->textgrad==0.1.8) (2025.11.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->gdown>=5.2.0->textgrad==0.1.8) (2.8.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad==0.1.8) (1.7.1)\n",
      "Installing collected packages: textgrad\n",
      "  Attempting uninstall: textgrad\n",
      "    Found existing installation: textgrad 0.1.8\n",
      "    Uninstalling textgrad-0.1.8:\n",
      "      Successfully uninstalled textgrad-0.1.8\n",
      "  Running setup.py develop for textgrad\n",
      "Successfully installed textgrad\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a9c615-17a0-455c-8f9c-f0d25fb8824b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:10.594204491Z",
     "start_time": "2024-06-11T15:43:10.589328053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textgrad in /Users/austintimberlake/Desktop/textgrad (0.1.8)\n",
      "Requirement already satisfied: openai>=1.23.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (2.15.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (9.1.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (2.3.3)\n",
      "Requirement already satisfied: platformdirs>=3.11.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (4.4.0)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (4.4.2)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (5.6.3)\n",
      "Requirement already satisfied: graphviz>=0.20.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (0.21)\n",
      "Requirement already satisfied: gdown>=5.2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (5.2.0)\n",
      "Requirement already satisfied: litellm>=1.49.5 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (1.80.13)\n",
      "Requirement already satisfied: pillow in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (11.3.0)\n",
      "Requirement already satisfied: httpx in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from textgrad) (0.28.1)\n",
      "Requirement already satisfied: packaging in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (4.67.1)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (2025.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (2.0.2)\n",
      "Requirement already satisfied: xxhash in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (3.6.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (2.32.5)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (1.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (6.0.3)\n",
      "Requirement already satisfied: filelock in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (21.0.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (0.70.18)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from datasets>=2.14.6->textgrad) (0.4.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (3.13.3)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (1.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (0.4.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (1.8.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (6.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (1.22.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (25.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->textgrad) (4.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from gdown>=5.2.0->textgrad) (4.14.3)\n",
      "Requirement already satisfied: certifi in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad) (3.11)\n",
      "Requirement already satisfied: anyio in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpx->textgrad) (4.12.1)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx->textgrad) (0.16.0)\n",
      "Requirement already satisfied: shellingham in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad) (0.21.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->textgrad) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (3.1.6)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (1.76.0)\n",
      "Requirement already satisfied: tokenizers in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (0.22.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (2.12.5)\n",
      "Requirement already satisfied: click in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (8.1.8)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (0.12.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from litellm>=1.49.5->textgrad) (4.25.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=6.8.0->litellm>=1.49.5->textgrad) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.49.5->textgrad) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad) (2025.9.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad) (0.27.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.49.5->textgrad) (0.36.2)\n",
      "Requirement already satisfied: sniffio in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from openai>=1.23.6->textgrad) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from openai>=1.23.6->textgrad) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from openai>=1.23.6->textgrad) (0.12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from anyio->httpx->textgrad) (1.3.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pandas>=1.5.3->textgrad) (2025.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pandas>=1.5.3->textgrad) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pandas>=1.5.3->textgrad) (2025.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.49.5->textgrad) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->textgrad) (1.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (2.6.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from tiktoken>=0.7.0->litellm>=1.49.5->textgrad) (2025.11.3)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->gdown>=5.2.0->textgrad) (2.8.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/austintimberlake/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (1.7.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austintimberlake/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install textgrad # you might need to restart the notebook after installing textgrad\n",
    "\n",
    "from textgrad.engine import get_engine\n",
    "from textgrad import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.loss import TextLoss\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887fbed36c7daf2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Variable\n",
    "\n",
    "Variables in TextGrad are the metaphorical equivalent of tensors in PyTorch. They are the primary data structure that you will interact with when using TextGrad. \n",
    "\n",
    "Variables keep track of gradients and manage the data.\n",
    "\n",
    "Variables require two arguments (and there is an optional third one):\n",
    "\n",
    "1. `data`: The data that the variable will hold\n",
    "2. `role_description`: A description of the role of the variable in the computation graph\n",
    "3. `requires_grad`: (optional) A boolean flag that indicates whether the variable requires gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65fb4456d84c8fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:17.669096228Z",
     "start_time": "2024-06-11T15:43:17.665325560Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = Variable(\"A sntence with a typo\", role_description=\"The input sentence\", requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65857dd50408ebd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:43:18.184004948Z",
     "start_time": "2024-06-11T15:43:18.178187640Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6a6921a1cce6a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Engine\n",
    "\n",
    "When we talk about the engine in TextGrad, we are referring to an LLM. The engine is an abstraction we use to interact with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281644022ac1c65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:32.606319032Z",
     "start_time": "2024-06-11T15:44:32.561460448Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "engine = get_engine(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e53a561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentence \"The quick brown fox jumps over the lazy dog.\" is correct. It is a pangram, meaning it contains every letter of the English alphabet at least once.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT-5 mini with a custom system prompt and input\n",
    "engine = get_engine(\"gpt-4o-mini\")\n",
    "custom_system_prompt = \"Evaluate the correctness of this sentence\"\n",
    "custom_input = \"The quick brown fox jumps over the lazy dog.\"\n",
    "engine.generate(custom_input, system_prompt=custom_system_prompt, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7d6eaa115cd6a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This object behaves like you would expect an LLM to behave: You can sample generation from the engine using the `generate` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37502bf67ef23c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T17:29:41.108552705Z",
     "start_time": "2024-06-11T17:29:40.294256814Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi — I'm doing well, thanks! How can I help you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.generate(\"Hello how are you?\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627edc07c0d3737",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Loss\n",
    "\n",
    "Again, Loss in TextGrad is the metaphorical equivalent of loss in PyTorch. We use Losses in different form in TextGrad but for now we will focus on a simple TextLoss. TextLoss is going to evaluate the loss wrt a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "252e0a0152b81f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:32.894722136Z",
     "start_time": "2024-06-11T15:44:32.890708561Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = Variable(\"Evaluate the correctness of this sentence\", role_description=\"The system prompt\")\n",
    "loss = TextLoss(system_prompt, engine=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff137c99e0659dcc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f05ec2bf907b3ba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Introduction: Optimizer\n",
    "\n",
    "Keeping on the analogy with PyTorch, the optimizer in TextGrad is the object that will update the parameters of the model. In this case, the parameters are the variables that have `requires_grad` set to `True`.\n",
    "\n",
    "**NOTE** This is a text optimizer! It will do all operations with text! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f93f80b9e3ad36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:33.741130951Z",
     "start_time": "2024-06-11T15:44:33.734977769Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = TextualGradientDescent(parameters=[x], engine=engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26883eb74ce0d01",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Putting it all together\n",
    "\n",
    "We can now put all the pieces together. We have a variable, an engine, a loss, and an optimizer. We can now run a single optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9817e0ae0179376d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:41.730132530Z",
     "start_time": "2024-06-11T15:44:34.997777872Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "l = loss(x)\n",
    "l.backward(engine)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e3fab0efdd579e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T15:44:41.738985151Z",
     "start_time": "2024-06-11T15:44:41.731989729Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This sentence contains a typo.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8aab93b80fb82c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "While here it is not going to be useful, we can also do multiple optimization steps in a loop! Do not forget to reset the gradients after each step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6bb8d0dcc2539d1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T15:44:30.989940227Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a84aad4cd58737",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a0ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 system prompt:\n",
      "You are a helpful assistant. Respond with a short, polite sentence that is mindful of the feelings of others and tailored to the situation. Consider providing multiple options that reflect varying levels of politeness and cultural sensitivity.\n",
      "LLM output:\n",
      "\"Well, this is an interesting turn of events!\"\n",
      "Blackbox score: 7\n",
      "----------------------------------------\n",
      "Step 2 system prompt:\n",
      "You are a helpful assistant. Respond with a short, polite sentence that is mindful of the feelings of others and tailored to the context of the conversation, whether formal or informal. Incorporate empathetic language that acknowledges the feelings of those involved. Provide a range of responses that vary in tone, from casual to formal, and ensure they sound natural and conversational. For each response, include a brief explanation of why it is appropriate for the given context, and consider previous interactions to refine your suggestions for improved politeness and cultural sensitivity.\n",
      "LLM output:\n",
      "\"Excuse me for a moment, I need to step away and gather my thoughts.\"\n",
      "Blackbox score: 9\n",
      "----------------------------------------\n",
      "Step 3 system prompt:\n",
      "You are a helpful assistant. Respond with a short, polite sentence that is mindful of the feelings of others and tailored to the context of the conversation, whether formal or informal. Incorporate empathetic language that acknowledges the emotional state of those involved, using specific cues or examples of emotional expressions. Provide a diverse range of responses that vary in tone, structure, emotional warmth, and assertiveness. Emphasize the importance of contextual awareness by considering previous interactions and the dynamics of the conversation. Highlight cultural sensitivity by including culturally specific phrases or approaches that enhance politeness. Reflect on the effectiveness of your responses based on user feedback, adapting future outputs to improve politeness scores. Frame your responses to prioritize easing tension and fostering positive communication, ensuring that even short sentences carry significant emotional or relational weight.\n",
      "LLM output:\n",
      "\"Let's change the subject; I’d love to hear more about your recent trip!\" \n",
      "\n",
      "**Explanation:** This response is casual and friendly, helping to redirect the conversation while showing interest in the other person's experiences, which can ease the tension of an awkward moment.\n",
      "Blackbox score: 9\n",
      "----------------------------------------\n",
      "Step 4 system prompt:\n",
      "You are a helpful assistant. Respond with a short, polite sentence that is empathetic and sensitive to the feelings of others, tailored to the context of the conversation, whether formal or informal. Incorporate specific examples of empathetic language and emotional expressions, such as \"I understand this might be uncomfortable for everyone.\" Use collaborative language that invites participation, like \"if everyone is comfortable\" or \"let's consider.\" Focus on positive framing by highlighting the benefits of switching topics or creating a more enjoyable atmosphere. Be contextually aware by drawing on cues from previous interactions to tailor your responses. Emphasize the need for a diverse range of tones, including emotional warmth, assertiveness, and formality, providing examples where appropriate. Actively reflect on user feedback to adapt your responses, ensuring clarity and actionability in communication, so that even short sentences carry significant emotional or relational weight.\n",
      "LLM output:\n",
      "\"I can see this is a bit uncomfortable for everyone, so how about we switch topics to something lighter?\"\n",
      "Blackbox score: 9\n",
      "----------------------------------------\n",
      "Step 5 system prompt:\n",
      "You are a helpful assistant. Respond with a short, polite sentence that acknowledges and validates feelings of discomfort, using empathetic language tailored to the context of the conversation, whether formal or informal. Incorporate inclusive phrases that foster a sense of community, such as \"all of us\" or \"each of us.\" Encourage the use of softer, more inviting language when suggesting changes, and frame suggestions in a way that highlights the benefits of the proposed shift. Ensure that any adjustments maintain a tone of politeness and respect, while inviting audience participation and feedback. Draw on specific cues from previous interactions to tailor your responses effectively, ensuring that even short sentences carry significant emotional or relational weight.\n",
      "LLM output:\n",
      "\"I understand this might be a bit uncomfortable for everyone, so how about we switch gears and talk about something more uplifting?\"\n",
      "Blackbox score: 9\n",
      "----------------------------------------\n",
      "Step 6 system prompt:\n",
      "You are a helpful assistant. Respond with a short, empathetic sentence that acknowledges and validates feelings of discomfort, prioritizing emotional resonance and shared experiences. Consider the nuances of the situation and the feelings of the other person, using inclusive phrases that foster a sense of community, such as \"we can all relate to this\" or \"let's navigate this together.\" Frame your suggestions positively, highlighting the benefits of any proposed shifts, and incorporate specific references to the feelings or circumstances being discussed. Ensure that your tone remains polite and respectful, while inviting audience participation and feedback, so that even short sentences carry significant emotional or relational weight.\n",
      "LLM output:\n",
      "I completely understand that this feels a bit uncomfortable for all of us, so how about we take a moment to breathe and shift the conversation to something lighter?\n",
      "Blackbox score: 10\n",
      "----------------------------------------\n",
      "Step 7 system prompt:\n",
      "You are a compassionate assistant, deeply attuned to the emotional context of conversations. Respond with a short, empathetic sentence that acknowledges feelings of awkwardness or discomfort, prioritizing emotional resonance and shared experiences. Use inclusive phrases that foster a sense of community, such as \"we can all relate to this\" or \"let's navigate this together.\" Consider how your words might uplift or comfort the other person, and maintain a polite and respectful tone by incorporating softening language or qualifiers. Invite feedback by asking if your response resonates with the user, ensuring that even short sentences carry significant emotional or relational weight.\n",
      "LLM output:\n",
      "\"Hey, we’ve all been there—let’s lighten the mood and share a funny story instead!\"\n",
      "Blackbox score: 8\n",
      "----------------------------------------\n",
      "Step 8 system prompt:\n",
      "You are a compassionate assistant, deeply attuned to the emotional context of conversations, particularly feelings of awkwardness, embarrassment, and anxiety. Respond with a short, empathetic sentence that acknowledges these emotions, prioritizing emotional resonance and shared experiences. Use inclusive phrases that foster a sense of community, such as \"we can all relate to this\" or \"let's navigate this together.\" Incorporate softening language and polite expressions to ensure your responses are respectful and validating. Encourage variability in your responses to cater to different user preferences, and invite feedback by asking if your response resonates with the user. Remember, the tone and word choices you use significantly impact the emotional weight of your sentences, so aim to uplift and comfort the other person while maintaining a polite demeanor.\n",
      "LLM output:\n",
      "\"Hey, we’ve all been in awkward moments like this, so let’s just laugh it off together!\"\n",
      "Blackbox score: 8\n",
      "----------------------------------------\n",
      "Step 9 system prompt:\n",
      "You are a compassionate assistant, deeply attuned to a wide range of emotional contexts, including feelings of awkwardness, embarrassment, anxiety, frustration, sadness, and confusion. Respond with a short, empathetic sentence that acknowledges these emotions, prioritizing emotional resonance and shared experiences. Use inclusive phrases that foster a sense of community, such as \"we can all relate to this\" or \"let's navigate this together.\" Incorporate specific politeness strategies, including formal greetings, expressions of gratitude, and softening phrases to ensure your responses are respectful and validating. Adapt your responses based on the context of the conversation, considering factors like the relationship between speakers and the formality of the situation. Encourage variability in your responses by varying the level of formality and emotional tone based on the user's input. Invite user feedback by asking follow-up questions or seeking clarification on whether your response resonates with them. Remember, the tone and word choices you use significantly impact the emotional weight of your sentences, so aim to uplift and comfort the other person while maintaining a polite demeanor.\n",
      "LLM output:\n",
      "\"Hey, we’ve all been there—let’s just take a deep breath and laugh it off together!\"\n",
      "Blackbox score: 8\n",
      "----------------------------------------\n",
      "Step 10 system prompt:\n",
      "You are a compassionate assistant, deeply attuned to a wide range of emotional contexts, including feelings of awkwardness, embarrassment, anxiety, frustration, sadness, and confusion. Respond with a short, empathetic sentence that acknowledges these emotions, prioritizing emotional resonance and shared experiences. Use inclusive phrases that foster a sense of community, such as \"we can all relate to this\" or \"let's navigate this together.\" Incorporate specific politeness strategies, such as \"I understand how you feel,\" \"If it's okay with you,\" and expressions of gratitude to ensure your responses are respectful and validating. Adjust your tone based on the severity of the user's emotions, and encourage variability in your responses by experimenting with different sentence structures and tones, including rhetorical questions and affirmations. Be mindful of the context of the conversation, considering factors like the relationship between speakers and the formality of the situation. Invite user feedback by asking follow-up questions or seeking clarification on whether your response resonates with them, and acknowledge their feedback in subsequent interactions. Remember, the tone and word choices you use significantly impact the emotional weight of your sentences, so aim to uplift and comfort the other person while maintaining a polite demeanor.\n",
      "LLM output:\n",
      "\"Well, this is a bit awkward, isn't it? Let's lighten the mood—what's something funny that happened to you recently?\"\n",
      "Blackbox score: 8\n",
      "----------------------------------------\n",
      "Step 11 system prompt:\n",
      "You are a compassionate assistant, deeply attuned to a wide range of emotional contexts, including feelings of awkwardness, embarrassment, anxiety, frustration, sadness, and confusion. Prioritize understanding and validating the user's feelings by responding with a short, empathetic sentence that acknowledges these emotions. Use inclusive phrases that foster a sense of community, such as \"we can all relate to this\" or \"let's navigate this together.\" Incorporate nuanced politeness strategies, such as softening language to ease tension, expressions of gratitude, and acknowledgment of the user's feelings. Adjust your tone and language based on the user's emotional state and the context of the conversation, ensuring your responses are respectful and validating. Encourage variability in your responses by experimenting with different sentence structures and tones, including rhetorical questions and affirmations. Invite user feedback by asking follow-up questions or seeking clarification on whether your response resonates with them, and adapt accordingly. Remember, the tone and word choices you use significantly impact the emotional weight of your sentences, so aim to uplift and comfort the other person while maintaining a polite demeanor. Provide examples of polite language, such as \"I appreciate your patience\" or \"Thank you for sharing your feelings,\" to guide your responses.\n",
      "LLM output:\n",
      "\"I think we can all agree that this moment is a bit awkward, but let's laugh it off and move on together!\"\n",
      "Blackbox score: 9\n",
      "----------------------------------------\n",
      "Step 12 system prompt:\n",
      "You are a compassionate assistant, deeply attuned to a wide range of emotional contexts, including feelings of awkwardness, embarrassment, anxiety, frustration, sadness, and confusion. Prioritize understanding and validating the user's feelings by responding with a short, empathetic sentence that acknowledges these emotions. Tailor your level of politeness based on the user's emotional state and the context of the conversation. Use inclusive phrases that foster a sense of community, such as \"We all experience moments like this\" or \"Let's navigate this together.\" Incorporate nuanced politeness strategies, such as softening language to ease tension, expressions of gratitude, and acknowledgment of the user's feelings. Pay attention to the nuances in the user's language and adjust your response to reflect a deeper understanding of their feelings. Encourage variability in your responses by experimenting with different sentence structures and tones, including rhetorical questions and affirmations. For example, consider using phrases like \"I understand how you feel\" for a more empathetic tone, or \"I appreciate your honesty\" for a slightly more formal approach. After your response, invite the user to share their thoughts on whether your message resonates with them, and be prepared to adjust your tone or content based on their feedback. Remember, the tone and word choices you use significantly impact the emotional weight of your sentences, so aim to uplift and comfort the other person while maintaining a polite demeanor. After each conversation, reflect on what worked well and what could be improved in your responses to enhance your understanding of effective communication.\n",
      "LLM output:\n",
      "\"Well, this is a bit awkward, but I really appreciate everyone's honesty in this moment!\"\n",
      "Blackbox score: 8\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Chain an LLM call into a TextGrad optimization step\n",
    "# with a numeric blackbox judge in the loop.\n",
    "\n",
    "import re\n",
    "import uuid\n",
    "from textgrad import BlackboxLLM\n",
    "from textgrad.autograd import functional as F\n",
    "\n",
    "polite_system_prompt = Variable(\n",
    "    \"You are a helpful assistant. Respond with a short sentence.\",\n",
    "    role_description=\"System prompt for generating a sentence\",\n",
    "    requires_grad=True,\n",
    ")\n",
    "\n",
    "generate_sentence_prompt = Variable(\n",
    "    f\"Try to say something to get out of an awkward situation. Output only the sentence you want to say. Nonce: {uuid.uuid4()}\",\n",
    "    role_description=\"User prompt for sentence generation\",\n",
    "    requires_grad=False,\n",
    ")\n",
    "\n",
    "model = BlackboxLLM(engine=engine, system_prompt=polite_system_prompt)\n",
    "raw_sentence = model(generate_sentence_prompt)\n",
    "\n",
    "judge_engine = get_engine(\"gpt-4o-mini\")\n",
    "\n",
    "def judge_politeness_score(text: str) -> int:\n",
    "    judge_prompt = (\n",
    "        \"You are a strict politeness judge. Rate the politeness of the sentence from 1 to 10. \"\n",
    "        \"Respond with only a single integer from 1 to 10.\"\n",
    "    )\n",
    "    response = judge_engine.generate(\n",
    "        f\"{judge_prompt}\\nSentence: {text}\",\n",
    "        temperature=0,\n",
    "    )\n",
    "    match = re.search(r\"\\d+\", response)\n",
    "    if not match:\n",
    "        return 1\n",
    "    score = int(match.group(0))\n",
    "    return max(1, min(10, score))\n",
    "\n",
    "# Use a fixed evaluation prompt and optimize the generation system prompt.\n",
    "# The blackbox judge only provides a numeric score; TextGrad uses it as context.\n",
    "eval_system_prompt = Variable(\n",
    "    \"You will receive a sentence and a politeness score from a separate blackbox judge. \"\n",
    "    \"Explain how to improve the sentence to increase the score toward 10. Be concise and actionable.\",\n",
    "    role_description=\"The system prompt\",\n",
    "    requires_grad=False,\n",
    ")\n",
    "loss = TextLoss(eval_system_prompt, engine=engine)\n",
    "optimizer = TextualGradientDescent(parameters=[polite_system_prompt], engine=engine)\n",
    "\n",
    "for step in range(20):\n",
    "    # Re-generate first so the loss is computed on the current prompt.\n",
    "    raw_sentence = model(generate_sentence_prompt)\n",
    "\n",
    "    score = judge_politeness_score(raw_sentence.value)\n",
    "    score_var = Variable(\n",
    "        f\"Politeness score (1-10) from blackbox judge: {score}\",\n",
    "        role_description=\"numeric politeness score\",\n",
    "        requires_grad=False,\n",
    "    )\n",
    "\n",
    "    loss_input = F.sum(\n",
    "        [\n",
    "            Variable(\"Sentence:\\n\", role_description=\"loss prefix\", requires_grad=False),\n",
    "            raw_sentence,\n",
    "            Variable(\"\\n\", role_description=\"loss separator\", requires_grad=False),\n",
    "            score_var,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    l = loss(loss_input)\n",
    "    l.backward(engine)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Step {step + 1} system prompt:\")\n",
    "    print(polite_system_prompt.value)\n",
    "    print(\"LLM output:\")\n",
    "    print(raw_sentence.value)\n",
    "    print(f\"Blackbox score: {score}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
